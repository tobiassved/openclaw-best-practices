# OpenClaw & AI Agent Best Practices

> **A comprehensive guide to building, deploying, and operating AI agents responsibly with OpenClaw**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![OpenClaw](https://img.shields.io/badge/OpenClaw-Compatible-blue.svg)](https://github.com/tbsp/openclaw)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Quick Start](#quick-start)
- [Documentation](#documentation)
- [Security Model](#security-model)
- [Contributing](#contributing)

## ğŸ¯ Overview

This repository provides battle-tested guidelines, patterns, and anti-patterns for deploying AI agents in production environments. Based on real-world experience with OpenClaw, Claude Code, Codex, and other autonomous coding agents.

**Who is this for?**
- DevOps engineers deploying AI agent infrastructure
- Developers building agent-driven workflows
- Security teams auditing AI agent deployments
- Product managers defining agent capabilities and boundaries

**What you'll learn:**
- How to configure OpenClaw securely for production use
- Design patterns for responsible agent behavior
- Security mechanisms: sandboxing, permissions, rate limiting
- Error handling, monitoring, and observability
- Ethical guidelines for autonomous agent behavior
- Real-world case studies of what can go wrong (and how to prevent it)

## ğŸš€ Quick Start

### Pre-flight Security Checklist

Before deploying any AI agent to production:

- [ ] Review [OpenClaw Configuration Guide](docs/01-openclaw-config.md)
- [ ] Implement [Sandbox Isolation](docs/03-security-mechanisms.md#sandboxing)
- [ ] Set up [Permission Boundaries](docs/03-security-mechanisms.md#permissions)
- [ ] Configure [Rate Limiting](docs/03-security-mechanisms.md#rate-limiting)
- [ ] Establish [Monitoring & Alerts](docs/04-monitoring.md)
- [ ] Review [Ethical Guidelines](docs/05-ethical-guidelines.md)
- [ ] Complete [Security Audit Checklist](checklists/security-audit.md)

### Threat Model

AI agents present unique security challenges:

| Threat | Impact | Mitigation |
|--------|--------|------------|
| **Command Injection** | Critical | Sandbox all bash commands, validate inputs |
| **Data Exfiltration** | High | Network isolation, audit file access |
| **Resource Exhaustion** | High | Rate limiting, budget caps, timeouts |
| **Privilege Escalation** | Critical | Drop privileges, use least-privilege containers |
| **Prompt Injection** | Medium | Input validation, system prompt hardening |
| **Unintended Actions** | High | Approval workflows, dry-run mode, audit logs |

## ğŸ“š Documentation

### Core Guides

1. **[OpenClaw Configuration](docs/01-openclaw-config.md)**
   - Installation and setup
   - Security-first configuration
   - Environment isolation
   - Gateway and bridge protocols

2. **[Responsible Agent Design](docs/02-agent-design.md)**
   - Defining agent boundaries
   - Tool selection and scoping
   - Prompt engineering for safety
   - Approval workflows and human-in-the-loop

3. **[Security Mechanisms](docs/03-security-mechanisms.md)**
   - Docker sandboxing
   - Permission models
   - Rate limiting and budget controls
   - Network isolation
   - Credential management

4. **[Monitoring & Error Handling](docs/04-monitoring.md)**
   - Observability patterns
   - Error handling strategies
   - Logging and audit trails
   - Alerting and incident response

5. **[Ethical Guidelines](docs/05-ethical-guidelines.md)**
   - Transparency and disclosure
   - User consent and agency
   - Data privacy and retention
   - Bias and fairness considerations

6. **[Case Studies](docs/06-case-studies.md)**
   - Real incidents and lessons learned
   - Common failure modes
   - Post-mortems and prevention strategies

### Additional Resources

- [Security Audit Checklist](checklists/security-audit.md)
- [Agent Deployment Checklist](checklists/deployment.md)
- [Code Examples](examples/)
- [OpenClaw Skills Reference](docs/appendix-skills.md)

## ğŸ” Security Model

### Defense in Depth

OpenClaw agent security relies on multiple layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Rate Limiting & Budget Caps       â”‚  â† Cost & abuse protection
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Permission System & Approval Flows    â”‚  â† User consent & control
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Tool Allowlists & Input Validation    â”‚  â† Capability restrictions
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Docker Sandbox / Process Isolation    â”‚  â† Execution containment
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Network Policies & Firewall Rules     â”‚  â† Communication boundaries
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Audit Logging & Monitoring            â”‚  â† Detection & response
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Principle of Least Privilege

**Never grant agents more access than absolutely required:**

- Use `allowedTools` to restrict available capabilities
- Run agents in unprivileged containers
- Use separate credentials with minimal scopes
- Implement time-based access controls
- Audit all privileged operations

### Fail-Safe Defaults

**Design systems to fail safely:**

- Default to requiring approval (not bypassing)
- Timeout long-running operations
- Reject ambiguous or dangerous commands
- Log all failures for review
- Preserve state before destructive actions

## ğŸ› ï¸ Examples

### Secure Worker API Configuration

```python
# examples/secure-worker-api.py
import http.server
import subprocess
import json

ALLOWED_TOOLS = ['Read', 'Grep', 'Glob']  # Read-only tools
MAX_BUDGET = 0.50  # Cost cap per request
TIMEOUT = 300  # 5 minute timeout

def run_agent(prompt):
    cmd = [
        'claude', '-p',
        '--max-budget-usd', str(MAX_BUDGET),
        '--allowedTools', ' '.join(ALLOWED_TOOLS),
        '--dangerously-skip-permissions',  # Only in isolated sandbox!
        prompt
    ]
    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        timeout=TIMEOUT,
        cwd='/workspace',  # Restricted working directory
        env={'HOME': '/tmp'}  # Minimal environment
    )
    return result.stdout
```

See [examples/](examples/) for more patterns.

## ğŸ—ï¸ Architecture Patterns

### Pattern 1: Gatekeeper Agent

Use a supervisory agent to review and approve actions:

```
User Request â†’ Orchestrator Agent â†’ [Approval Check] â†’ Worker Agent â†’ Execution
```

### Pattern 2: Read-Only Exploration

Separate read and write permissions across agent stages:

```
Phase 1: Exploration Agent (Read-only tools) â†’ Analysis
Phase 2: Human Review â†’ Approval
Phase 3: Execution Agent (Write tools) â†’ Changes
```

### Pattern 3: Sandboxed Validation

Test changes in isolation before applying to production:

```
Agent â†’ Sandbox Environment â†’ Run Tests â†’ [Pass] â†’ Apply to Production
```

## ğŸ“Š Monitoring Essentials

### Key Metrics

- **API Cost**: Track spending per agent, session, and user
- **Tool Usage**: Monitor which tools are invoked and how often
- **Error Rates**: Alert on elevated failure rates
- **Execution Time**: Detect hanging or runaway processes
- **Permission Denials**: Investigate blocked operations

### Alert Thresholds

```yaml
alerts:
  - name: high_api_cost
    threshold: 5 USD/hour
    action: page_on_call

  - name: elevated_bash_usage
    threshold: 50 commands/session
    action: notify_security_team

  - name: permission_bypass_attempt
    threshold: 1 occurrence
    action: terminate_session
```

## âš–ï¸ Ethical Considerations

### Transparency

**Users must know when they're interacting with an AI agent:**

- Clearly label agent-generated content
- Disclose agent capabilities and limitations
- Provide opt-out mechanisms
- Document data retention policies

### Accountability

**Establish clear ownership and responsibility:**

- Human oversight for high-impact decisions
- Audit trails for all agent actions
- Rollback procedures for mistakes
- Incident response plans

### Bias & Fairness

**Agents inherit biases from training data:**

- Test for bias in decision-making
- Provide mechanisms for feedback and correction
- Document known limitations
- Regular bias audits

## ğŸ§ª Testing & Validation

### Pre-Deployment Checklist

- [ ] Unit tests for permission boundaries
- [ ] Integration tests with real agent sessions
- [ ] Penetration testing (command injection, etc.)
- [ ] Load testing (rate limits, resource exhaustion)
- [ ] Chaos engineering (network failures, timeouts)
- [ ] Red team review of security controls

### Continuous Validation

- Automated security scans on configuration changes
- Regular credential rotation
- Dependency vulnerability scanning
- Agent behavior audits

## ğŸ¤ Contributing

Contributions welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) first.

**Areas where we need help:**
- Additional case studies and post-mortems
- Security patterns for specific deployment scenarios
- Tool-specific hardening guides
- Translations to other languages

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- OpenClaw project and community
- Anthropic for Claude Code
- OpenAI for Codex
- Security researchers who've shared their findings

## ğŸ“ Contact

- **Security Issues**: security@[your-domain] (private disclosure)
- **General Questions**: GitHub Issues
- **Discussions**: GitHub Discussions

---

**âš ï¸ Important Disclaimer**

AI agents are powerful tools that require careful deployment. This guide provides recommendations based on current best practices, but security is an evolving field. Always perform your own security assessment before deploying agents in production environments.

**No warranty is provided. Use at your own risk.**
